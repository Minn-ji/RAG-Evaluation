{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd0a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 300/300 [00:00<00:00, 3016.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "EXAMPLE_DATASET=\"allganize/RAG-Evaluation-Dataset-KO\"\n",
    "dataset = load_dataset(EXAMPLE_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710c7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain, question, target_answer, target_file_name, target_page_no, alli_gpt-4_answer\n",
    "ds = dataset.select_columns([\"domain\", \"question\", \"target_answer\", \"target_file_name\", \"target_page_no\", \"alli_gpt-4_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a1db81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['domain', 'question', 'target_answer', 'target_file_name', 'target_page_no', 'alli_gpt-4_answer'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ragas.metrics import NonLLMContextPrecisionWithReference\n",
    "from ragas import SingleTurnSample\n",
    "\n",
    "async def precision():\n",
    "    context_precision = NonLLMContextPrecisionWithReference()\n",
    "\n",
    "    sample = [SingleTurnSample(\n",
    "        retrieved_contexts=[item.get(\"target_answ\")], \n",
    "        reference_contexts=[\"Paris is the capital of France.\", \"The Eiffel Tower is one of the most famous landmarks in Paris.\"]\n",
    "    ) for item in example]\n",
    "\n",
    "    await context_precision.single_turn_ascore(sample)\n",
    "\n",
    "\n",
    "def precision_at_k(self, retrieved_docs, ground_truth_ids, k) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Mean Precision@K for a set of queries.\n",
    "\n",
    "    Precision@K is the proportion of retrieved documents in the top K\n",
    "    that are relevant.\n",
    "    \"\"\"\n",
    "    all_precisions_at_k = []\n",
    "    for i, retrieved in enumerate(retrieved_docs):\n",
    "        relevant_ids_for_query = set(ground_truth_ids[i])\n",
    "        top_k_docs = sorted([d for d in retrieved if d['rank'] <= k], key=lambda x: x['rank'])\n",
    "        \n",
    "        hits = 0\n",
    "        for doc in top_k_docs:\n",
    "            if doc['doc_id'] in relevant_ids_for_query:\n",
    "                hits += 1\n",
    "        \n",
    "        precision_at_k = hits / k if k > 0 else 0.0\n",
    "        all_precisions_at_k.append(precision_at_k)\n",
    "        \n",
    "    return np.mean(all_precisions_at_k) if all_precisions_at_k else 0.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
